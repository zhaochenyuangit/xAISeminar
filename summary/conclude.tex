\section{Conclusion}\label{sec:Conclude}
Counterfactual explanation is a powerful tool to interpret a particular outcome from AI. The absence of internal details of the model and its resemblance to human logic benefit the lay audience in understanding a decision. What's more, the explanation potentially implies a solution to an undesired outcome. However, the mainstream of counterfactual explanation usually searches an example semantically with a distance function, which often violates the data distribution and results in an uninterpretable outcome similar to an adversarial example. To improve the interpretability and actionability of a counterfactual explanation, including causal models is a promising way. But related researches that based on directed graph can be hardly deployed due to the lack of clear causality connection in real life.    